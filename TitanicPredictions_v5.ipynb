{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dea4893b-a33f-4c70-b33a-4265bdb14bd1",
    "_uuid": "e2ae0dda-05df-4bee-ae8f-5b612c7276e8"
   },
   "source": [
    "# Titanic Survival Part 3: Training Classifiers for Accuracy\n",
    "\n",
    "In Part 1 of this project I conduct Exploratory Data Analysis (EDA) of the Titanic training data using R. This exploration can be found [here.](http://rpubs.com/BigBangData/512981)\n",
    "\n",
    "In Part 2 I continue the exploration using Python and building a couple of basic models. This is not intended as the goal of the competition, just an exploration of modeling in Python.\n",
    "\n",
    "In Part 3 (this notebook) I create a pre-processing pipeline and train several models in Python using the scikit-learn module, and submit my predictions to the competition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revised on: 2020-01-21\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "dt_object = datetime.fromtimestamp(time.time())\n",
    "dt_object = str(dt_object).split('.')[0]\n",
    "\n",
    "Date, Time = dt_object.split(' ')\n",
    "print('Revised on: ' + Date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "8ed67410-0b1c-4624-a678-425c37d80aa5",
    "_uuid": "15baa9c3-9543-4522-bfc5-e6cff3818b15"
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# custom modules\n",
    "import processing_pipeline as pp  \n",
    "import modeling_functions as mf\n",
    "\n",
    "# load training data\n",
    "train_data = pd.read_csv(\"../input/train.csv\")\n",
    "\n",
    "# separate target from predictors in training set\n",
    "survived_labels = train_data['Survived'].copy()\n",
    "train_data_nolabel = train_data.drop('Survived', axis=1)\n",
    "\n",
    "# get processed training data and labels\n",
    "X = pp.process_train(train_data_nolabel)\n",
    "y = survived_labels.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search with Random Forests\n",
    "\n",
    "I performed a grid search comparing `gini` and `entropy` information gain criteria, bootstrapping vs. not, and a sweep of the number of estimators from 50 to 5000 (by 250, so not very granular). We can expect an accuracy of about 82% from a model with the parameters below, so we'll test this assumption by training a model with these parameters and by comparing with the accuracy in the real test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'bootstrap': True, 'criterion': 'entropy', 'n_estimators': 300},\n",
       " 'Accuracy: 81.93%')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid_search_1 = pickle.load(open('./RandomForest_GridSearch.sav', 'rb'))\n",
    "rf_grid_search_1.best_params_ , 'Accuracy: ' + str(round(rf_grid_search_1.best_score_, 4)*100) + '%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Best RF model plus Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full data accuracy: 82.682%\n",
      "Important subset accuracy: 81.006%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# split training data into 20% test and 80% training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# train best RF classifier\n",
    "forest_clf = RandomForestClassifier(bootstrap=True, \n",
    "                                    criterion='entropy', \n",
    "                                    n_estimators=300, \n",
    "                                    random_state=42)\n",
    "forest_clf.fit(X_train, y_train)\n",
    "\n",
    "# select subset with most important features (threshold defined with elbow plot)\n",
    "sfm = SelectFromModel(forest_clf, threshold=0.0275)\n",
    "sfm.fit(X_train, y_train)\n",
    "\n",
    "# create subsets with most important features\n",
    "X_train_imp = sfm.transform(X_train)\n",
    "X_test_imp = sfm.transform(X_test)\n",
    "\n",
    "# train a new model on this subset\n",
    "forest_clf_imp =  RandomForestClassifier(bootstrap=True, \n",
    "                                        criterion='entropy', \n",
    "                                        n_estimators=300, \n",
    "                                        random_state=42)\n",
    "forest_clf_imp.fit(X_train_imp, y_train)\n",
    "\n",
    "# predict on the test set using the full dataset\n",
    "y_pred = forest_clf.predict(X_test)\n",
    "full_accuracy = str(round(accuracy_score(y_test, y_pred), 5)*100) + '%'\n",
    "\n",
    "# predict on the test set using the important subset model\n",
    "y_pred_imp = forest_clf_imp.predict(X_test_imp)\n",
    "important_accuracy = str(round(accuracy_score(y_test, y_pred_imp), 5)*100) + '%'\n",
    "\n",
    "print('Full data accuracy: ' + full_accuracy)\n",
    "print('Important subset accuracy: ' + important_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would seem as if the subset with the most important features slightly underperforms the full dataset, however, it's possible that the full dataset is overfitting, since we haven't performed any regularization. It will be interesting to compare the actual scores on the test set by submitting predictions using these two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process test dataset - avoid warning for the single NaN before re-imputing 'Age'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "test_data = pd.read_csv(\"../input/test.csv\")\n",
    "test_PassengerId = test_data['PassengerId'].copy()\n",
    "\n",
    "X_test = pp.process_test(test_data) # this only differs by 1 line, see code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_imp = sfm.transform(X_test)\n",
    "\n",
    "# get predictions using our two RF classifiers\n",
    "y_pred_full = forest_clf.predict(X_test)\n",
    "y_pred_imp = forest_clf_imp.predict(X_test_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full data CSV\n",
    "dict_full = { 'PassengerId': test_PassengerId, 'Survived': pd.Series(y_pred_full) } \n",
    "rf_full = pd.DataFrame(dict_full) \n",
    "rf_full.to_csv('./rf_full.csv', index=False)\n",
    "\n",
    "# important subset CSV\n",
    "dict_imp = { 'PassengerId': test_PassengerId, 'Survived': pd.Series(y_pred_imp) } \n",
    "rf_imp = pd.DataFrame(dict_imp) \n",
    "rf_imp.to_csv('./rf_imp.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Submissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My second submission, the full data random forest model which got 82.682% accuracy in validation, got 77.033% accuracy in the real test set, and 10,210th place. The third submission, the important subset, got the same exact score. This is just slightly better than the `gender submission` \"model\" which just predicts females survive, which is the example used in the competition for how one should format and submit predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with defaults: 83.24%\n",
      "Accuracy w/ best model: 83.80%\n",
      "Accuracy w/ third model: 82.12%\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# split training data into 20% test and 80% training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# default model\n",
    "xgb_def = XGBClassifier()\n",
    "xgb_def.fit(X_train, y_train)\n",
    "y_pred_def = xgb_def.predict(X_test)\n",
    "accuracy_def = accuracy_score(y_test, y_pred_def)\n",
    "\n",
    "\n",
    "xgb_best = XGBClassifier(objective='binary:logistic', \n",
    "                         colsample_bytree=0.8, \n",
    "                         learning_rate=0.15,\n",
    "                         n_estimators=150,\n",
    "                         random_state=42)\n",
    "\n",
    "# best model\n",
    "xgb_best.fit(X_train, y_train)\n",
    "y_pred_best = xgb_best.predict(X_test)\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "\n",
    "xgb_third = XGBClassifier(objective='binary:logistic', \n",
    "                          colsample_bytree=0.8, \n",
    "                          learning_rate=0.1,\n",
    "                          max_depth=3,\n",
    "                          n_estimators=250,\n",
    "                          reg_alpha=10,\n",
    "                          random_state=42)\n",
    "# a third model\n",
    "xgb_third.fit(X_train, y_train)\n",
    "y_pred_third = xgb_third.predict(X_test)\n",
    "accuracy_third = accuracy_score(y_test, y_pred_third)\n",
    "\n",
    "print(\"Accuracy with defaults: %.2f%%\" % (accuracy_def * 100.0))\n",
    "print(\"Accuracy w/ best model: %.2f%%\" % (accuracy_best * 100.0))\n",
    "print(\"Accuracy w/ third model: %.2f%%\" % (accuracy_third * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Entire Train Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I just submitted my first prediction in Kaggle and achieved the stunning result of being the **14,155th** entry in the leaderboard. (The leaderboard is quite heavily overfitted for this baby competition.) The XGBoost classifier which got 84.41% accuracy during validation got 73.68% accuracy on the real test set, so it lost 10% accuracy when generalizing - it was probably overfitting.\n",
    "\n",
    "In real life, I would have to stop now, you only get one chance, but since this is Kaggle, I will submit the SGD classifier and RF classifier as well to see whether simpler models generalized better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
